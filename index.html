<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Understanding Generative Flow Networks (GFlowNets) – A User perspective</title>
  <!-- Load Dagre first -->
<script src="https://unpkg.com/dagre/dist/dagre.min.js"></script>
<!-- KaTeX CSS -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/katex.min.css"
      integrity="sha384-zh0CIslj+VczCZtlzBcjt5ppRcsAmDnRem7ESsYwWwg3m/OaJ2l4x7YBZl9Kxxib" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/katex.min.js"
        integrity="sha384-Rma6DA2IPUwhNxmrB/7S3Tno0YY7sFu9WSYMCuulLhIqYSGZ2gKCJWIqhBWqMQfh" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/contrib/auto-render.min.js"
        integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>

        <script src="https://d3js.org/d3.v7.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/dagre@0.8.5/dist/dagre.min.js"></script>


<style>
  nav {
  position: fixed;
  top: 0;
  left: 0;
  width: 250px;
  height: 100vh;
  background: rgba(0,0,0,0.9);
  transform: translateX(-270px);
  transition: transform 0.3s ease;
  padding: 60px 20px;
  overflow-y: auto;
  z-index: 9999;
}
nav.show {
  transform: translateX(0);
}
.nav-menu {
  list-style: none;
}
.nav-menu li {
  margin-bottom: 15px;
}
.nav-menu a {
  color: #eee;
  text-decoration: none;
  font-weight: 600;
  font-size: 1rem;
}
.nav-menu a:hover {
  text-decoration: underline;
}
  details > summary + p + ul {
  margin-left: 2em;  /* or whatever spacing you prefer */
}

/* Optional: Some extra styling for math blocks */
.katex-display {
margin: 1em 0;
text-align: center;
}
code {
background-color: #f3f3f3;
padding: 2px 4px;
border-radius: 4px;
font-size: 90%;
}
details > summary {
cursor: pointer;
font-weight: bold;
}

* {
  margin: 0;
  padding: 0;
  box-sizing: border-box;
}
html, body {
  width: 100%;
  height: 100%;
  background: #111;
  color: #eee;
  font-family: "Helvetica Neue", Arial, sans-serif;
  line-height: 1.6;
  overflow-x: hidden;
}
/* (Line 20) Headings & Text */
h1, h2, h3, h4, h5, h6 {
  font-weight: 700;
  margin-bottom: 10px;
  color: #00bfff;
}
h1 {
  font-size: 2rem;
  margin-top: 80px;
  text-align: center;
  color: #00bfff;
}
h2 {
  margin-top: 40px;
  color: #fefefe;
}
p, li {
  margin-bottom: 10px;
}
a {
  color: #00bfff;
  text-decoration: none;
}
a:hover {
  text-decoration: underline;
}
em {
  font-style: italic;
}
code {
  background: rgba(255,255,255,0.07);
  padding: 3px 5px;
  border-radius: 4px;
  font-family: "Courier New", monospace;
}
pre {
  background: rgba(255,255,255,0.1);
  padding: 10px;
  border-radius: 6px;
  overflow-x: auto;
  margin: 15px 0;
}
/* (Line 50) Layout: main container */
main {
  max-width: 1200px;
  margin: 0 auto;
  padding: 60px 20px;
  position: relative;
  z-index: 1; /* Over the particle background */
}
/* (Line 60) Sections styling */
section {
  margin-bottom: 100px;
  background: rgba(255,255,255,0.02);
  border-radius: 6px;
  padding: 20px;
  transition: all 0.4s ease;
}
section.active {
  background: rgba(255,255,255,0.06);
  transform: translateY(-2px);
  box-shadow: 0 2px 8px rgba(0,0,0,0.5);
}
.section-content {
  margin: 0 10px;
}

/* (Line 75) Particle Background Container */
#particles-js {
  position: fixed;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  z-index: -10; /* behind everything */
}

/* (Line 80) Header & Burger Menu */
header {
  position: fixed;
  top: 10px;
  left: 10px;
  z-index: 9999;
}
.burger {
  width: 30px;
  height: 24px;
  display: flex;
  flex-direction: column;
  justify-content: space-between;
  cursor: pointer;
}
.burger span {
  display: block;
  height: 4px;
  background: #fff;
  border-radius: 2px;
}

/* (Line 100) Navigation (sidebar) */
nav {
  position: fixed;
  top: 0;
  left: 0;
  width: 250px;
  height: 100vh;
  background: rgba(0,0,0,0.9);
  transform: translateX(-270px);
  transition: transform 0.3s ease;
  padding: 60px 20px;
  overflow-y: auto;
  z-index: 9999;
}
nav.show {
  transform: translateX(0);
}
.nav-menu {
  list-style: none;
}
.nav-menu li {
  margin-bottom: 15px;
}
.nav-menu a {
  color: #eee;
  text-decoration: none;
  font-weight: 600;
  font-size: 1rem;
}
.nav-menu a:hover {
  text-decoration: underline;
}

/* (Line 125) The big page title H1 in the center */
h1 {
  margin-top: 120px;
  color: #00bfff;
  text-align: center;
  font-size: 2.4rem;
}

/* (Line 130) Sticky Arrow */
.sticky-arrow {
  position: fixed;
  bottom: 20px;
  right: 20px;
  background: #333;
  color: #fff;
  padding: 12px 15px;
  border-radius: 50%;
  cursor: pointer;
  font-size: 24px;
  z-index: 9999;
  text-align: center;
  line-height: 1;
  transition: background 0.3s;
}
.sticky-arrow:hover {
  background: #444;
}

/* (Line 145) Tetris container */
#tetris-game .container {
  display: flex;
  flex-wrap: wrap;
  gap: 24px;
  align-items: flex-start;
  justify-content: center;
}
#tetris-game .board {
  flex: 0 0 auto;
}
#tetris-game .sidebar {
  flex: 0 0 auto;
  min-width: 200px;
  max-width: 280px;
  background: rgba(0,0,0,0.3);
  padding: 15px;
  border-radius: 6px;
}
#tetrisCanvas {
  background: #222;
  border: 2px solid #444;
  display: block;
}

/* (Line 165) Candidate moves list */
#candidateList {
  margin-top: 10px;
}
.candidate {
  background: rgba(255,255,255,0.08);
  border-radius: 5px;
  padding: 8px;
  margin: 6px 0;
  cursor: pointer;
  transition: background 0.2s;
}
.candidate:hover {
  background: rgba(255,255,255,0.15);
}
.controls button {
  margin-top: 10px;
  padding: 10px 16px;
  background: #00bfff;
  border: none;
  border-radius: 4px;
  font-weight: 600;
  cursor: pointer;
  color: #111;
}
.controls button:hover {
  opacity: 0.85;
}

/* (Line 185) Collapsible details */
details {
  background: rgba(255,255,255,0.07);
  padding: 10px;
  border-radius: 5px;
  margin: 20px 0;
}
details summary {
  cursor: pointer;
  font-size: 1.05rem;
  font-weight: 600;
}
details summary::-webkit-details-marker {
  display: none;
}
details summary:before {
  content: '► ';
  color: #ffcc00;
}
details[open] summary:before {
  content: '▼ ';
  color: #ffcc00;
}

/* (Line 200) Reference lists */
.references {
  margin-top: 25px;
  background: rgba(255,255,255,0.04);
  padding: 10px;
  border-radius: 5px;
}
.references h3 {
  margin-bottom: 10px;
}
.references ul, .references ol {
  margin-left: 20px;
}
.references li {
  margin-bottom: 5px;
  line-height: 1.4;
}

#comparisonChart {
  display: flex;
  justify-content: center;   /* center them horizontally */
  gap: 20px;                 /* some spacing between the two mini DAGs */
}


/* (Line 230) Footer */
footer {
  text-align: center;
  padding: 20px 0;
  margin-top: 40px;
  background: rgba(255,255,255,0.02);
  border-top: 1px solid #444;
}



    /* Your existing dark-mode styles truncated for brevity... */
    html, body {
      background: #111;
      color: #eee;
      /* etc... */
    }

    /*
      Force KaTeX text to inherit the same color you use for
      the rest of the page. Otherwise KaTeX may default to black.
    */
    .katex, .katex-html, .katex-display {
      color: inherit !important;
    }

    /* Make display equations more readable against dark background */
    .katex-display {
      margin: 1em auto;
      text-align: center;
      font-size: 1.1rem; /* adjust if you want bigger/smaller math */
      line-height: 1.4;
    }

        /* =============== KaTeX Styling for Dark Mode =============== */
    /* Let KaTeX inherit the page's light text color */
    .katex, .katex-display, .katex-html {
      color: #f0f0f0 !important;
      /* 
         If you still see black text, your browser may be caching KaTeX font files 
         or there's another conflicting style. A hard refresh or clearing cache helps.
      */
    }

    /* Make inline math slightly larger than default */
    .katex {
      font-size: 1.06rem; 
      line-height: 1.5;
    }

    /* For display math (the $$ ... $$ kind): bigger, with a subtle background box */
    .katex-display {
      font-size: 1.15rem;
      line-height: 1.45;
      margin: 1.4em auto; 
      padding: 0.8em 1em;
      background: rgba(255,255,255,0.07);
      border-radius: 8px;
      box-shadow: 0 0 8px rgba(0,0,0,0.5);
      text-align: left; /* or center, if you prefer */
      max-width: 95%;
    }

    /*
       Improve fraction lines, roots, etc. on dark backgrounds
       KaTeX sets them as border-color, so let's override them
    */
    .katex .frac-line, 
    .katex .sqrt-line {
      border-color: #bbb !important;
    }

    /*
       Tweak the color for things like \tag, equation numbers, etc.
    */
    .katex-html .tag {
      background: #222 !important; 
      color: #ffcc00 !important; 
      border-radius: 4px;
      padding: 0 4px;
    }

    header {
  position: fixed;
  top: 10px;
  left: 10px;
  z-index: 99999; /* Higher than the nav */
}
.burger {
  width: 30px;
  height: 24px;
  display: flex;
  flex-direction: column;
  justify-content: space-between;
  cursor: pointer;
  /* optionally a background or small padding to ensure it's visible */
}

body {
  display: flex;
  flex-direction: column;
  min-height: 100vh;
  margin: 0;
  padding: 0;
}

main {
  flex: 1;
}

footer {
  flex-shrink: 0;
}
  </style>

</head>
<body>
<!-- (Line 250) Particle background container -->
<div id="particles-js"></div>

<!-- (Line 252) Header with burger menu button -->
<header>
  <div id="burger" class="burger" onclick="toggleNavMenu()">
    <span></span>
    <span></span>
    <span></span>
  </div>
</header>

<!-- (Line 260) Main page title -->
<h1>Understanding Generative Flow Networks (GFlowNets): A User perspective</h1>

<!-- (Line 262) Sidebar Navigation -->
<nav id="mainNav">
  <ul class="nav-menu">
    <li><a href="#introduction">1. Introduction: Generative Flow Networks</a></li>
    <li><a href="#tetris-demo">2. Tetris GFlowNet Demo</a></li>
    <li><a href="#motivation">3. Understanding GFlowNets</a></li>
    <li><a href="#theory">4. Core Concepts</a></li>
    <li><a href="#advanced-math">5. Advanced Math</a></li>
  </ul>
</nav>


<!-- (Line 275) Sticky arrow to scroll down or up -->
<div id="stickyArrow" class="sticky-arrow" onclick="scrollDown()">
  &#x2193;
</div>


<!-- (Line 280) MAIN CONTENT -->
<main>
  <section id="introduction">
    <div class="section-content">
      <h2>1. Introduction: Generative Flow Networks (GFlowNets)</h2>
      
      <p>
        A <strong>Generative Flow Network (GFlowNet)</strong> is a generative model 
        that learns to produce <em>multiple</em> high-quality solutions 
        (e.g., game moves, molecule designs) in proportion to their “reward.” 
        In other words, it does not just chase a single best path like many 
        <strong>traditional AI</strong> methods like reinforcement learning. Instead it maintains a 
        <em>diverse distribution</em> over near-optimal solutions. 
      </p>
  
      <p>
        Why does this matter? Because in real-world scenarios 
        like <strong>drug discovery</strong> or <strong>Tetris</strong>, you often want a <em>range</em> of 
        strong candidates. This way you can explore them all in parallel in the real world, if one fails another one might succeed. GFlowNets handle 
        this by learning to <em>flow</em> probability across all good options, which 
        leads to broader exploration and <strong>robustness</strong> when conditions change.
      </p>
  
      <!-- Comparison Chart: single-path vs. multi-path -->
      <div id="comparisonChart" style="width:100%; height:auto; min-height:400px;"></div>
      <script src="static/comparison.js"></script>
      <script>
        document.addEventListener("DOMContentLoaded", function() {
          initComparisonChart();
        });
      </script>
  
      <p>
        The comparison below highlights how “Traditional RL” may fixate on 
        one route, while a “GFlowNet” balances probability across many. 
        If you imagine each <em>path</em> as a way to build a solution, a GFlowNet 
        keeps multiple paths viable. This is especially helpful when you can not be sure 
        which path is truly the best.
      </p>
  
      <div class="references">
        <h3>Further Reading – Introduction</h3>
        <ul>
          <li>
            <strong>[1]</strong>
            Bengio, Y. et al. 
            <a href="https://arxiv.org/pdf/2106.04399.pdf" target="_blank">
              <em>Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation</em>
            </a>
            (NeurIPS 2021)
          </li>
          <li>
            <strong>[2]</strong>
            Bengio, Y. et al.
            <a href="https://arxiv.org/pdf/2111.09266.pdf" target="_blank">
              <em>GFlowNet Foundations</em>
            </a>
            (arXiv 2021)
          </li>
        </ul>
      </div>
    </div>
  </section>
  
  
  

  <!-- 
    =================================================================================
    SECTION 1: TETRIS DEMO
    We put the Tetris game first to wow the user. 
    The Tetris logic is embedded as "main.js" at the bottom, inlined for completeness.
    =================================================================================
  -->
  <section id="tetris-demo">
    <div class="section-content">
      <h2>2. Tetris GFlowNet Demo</h2>
      <p>
        Here, you can watch a <strong>GFlowNet</strong> in action, guiding an 
        interactive Tetris game. At each step, the system identifies multiple 
        promising moves—each assigned a <em>“flow”</em> value indicating how strongly 
        the GFlowNet favors it. Notably, it does not just stick to the 
        single most probable move, but it occasionally samples less-likely options, 
        ensuring exploration. Over time, it balances trying new strategies with 
        maximizing the reward (in this case, staying alive in Tetris for as long as possible). 
        This way the GFlowNet aims to match the real distribution of each move. 
      </p>
  
      <p>
        In the panel on the right, you will see the current top moves. 
        The GFlowNet automatically picks the best one (highlighted in green), 
        but you are free to override it by clicking on any other move 
        to see how that might affect the game.
      </p>
    </div>
  
    <!-- Actual Tetris Canvas & Moves -->
    <section id="tetris-game">
      <div class="container">
        <div class="board">
          <canvas id="tetrisCanvas" width="300" height="600"></canvas>
        </div>
        <div class="sidebar">
          <h2>Candidate Moves</h2>
          <div id="candidateList"><!-- Populated by Tetris logic --></div>
          <div class="controls">
            <button id="resetBtn">Reset Game</button>
          </div>
        </div>
      </div>
    </section>
  
    <div class="references">
      <h3>Further Reading – Tetris GFlowNet Demo</h3>
      <ul>
        <li>
          <strong>[1]</strong>
          Pan, L. et al.
          <a href="https://arxiv.org/pdf/2302.09465.pdf" target="_blank">
            <em>Stochastic Generative Flow Networks</em>
          </a>
          (arXiv 2023)
        </li>
        <li>
          <strong>[2]</strong>
          Jain, M. et al.
          <a href="https://arxiv.org/pdf/2203.04115.pdf" target="_blank">
            <em>Biological Sequence Design with GFlowNets</em>
          </a>
          (arXiv 2022)
        </li>
      </ul>
    </div>
  </section>
  


  <section id="motivation">
    <div class="section-content">
      <h2>3. Understanding GFlowNets</h2>
      
      <p>
        GFlowNets learn to generate different solutions by giving each one a chance 
        based on how “good” it is. If a solution is better (or has a higher “reward”), 
        the GFlowNet will pick it more often. This also leaves room for other strong 
        solutions, so you do not get stuck with just a single “winner.”
      </p>
  
      <p>
        A helpful way to picture this is to imagine water flowing through a network 
        of pipes. Each node in the network is a partial step toward a final solution. 
        Each edge is a possible move that sends some of the water forward. A reward 
        acts like the size of the container at the end of each path: bigger rewards 
        gather more water, so those solutions appear more frequently. Smaller rewards 
        still collect some water too, which prevents them from being ignored.
      </p>
  
      <p>
        This design relies on <em>flow conservation</em>. It means any flow that enters 
        a node must exit it along one of the available paths. Nothing is lost or created 
        midstream. In practice, this simple rule ensures that high-reward solutions end 
        up with more flow, yet other options receive some flow as well. The diagram below 
        illustrates how different paths share in this flow of probability, making 
        GFlowNets valuable for tasks that need multiple strong outcomes.
      </p>
      
      <!-- Flow Conservation Demo -->
      <div id="flowConservationContainer">
        <svg id="flowConservationSVG"></svg>
      </div>
      <script src="/static/flow_conservation.js"></script>
      <script>
        document.addEventListener("DOMContentLoaded", function() {
          initFlowConservationDemo();
        });
      </script>
  
      <div class="references">
        <h3>Further Readings on GFlowNets</h3>
        <ul>
          <li>
            <strong>[1]</strong>
            Tiapkin, D. et al.
            <a href="https://arxiv.org/pdf/2310.12934.pdf" target="_blank">
              <em>Generative Flow Networks as Entropy-Regularized RL</em>
            </a>
            (arXiv 2023)
          </li>
          <li>
            <strong>[2]</strong>
            Zhang, D. et al.
            <a href="https://arxiv.org/pdf/2209.02606.pdf" target="_blank">
              <em>Unifying Generative Models with GFlowNets and Beyond</em>
            </a>
            (arXiv 2022)
          </li>
        </ul>
      </div>
    </div>
  </section>
  
  
  

  

  <!-- =================================================================================
SECTION 4: GFlowNet Core Concepts & Flow Conservation with Molecule Visualization
================================================================================= -->
<section id="theory">
  <div class="section-content">
    <h2>4. Core Concepts & Flow Conservation</h2>
    
    <p>
      In this section, we take a look at how GFlowNets can help build complex objects like molecules. 
      The idea is to treat each molecule as a path in a Directed Acyclic Graph (DAG), where each node represents 
      a partial structure and each edge represents an action that adds or changes something about that structure. 
      You progress step by step until you reach a fully formed molecule at a terminal node.
    </p>
    
    <p>
      The principle of <strong>flow conservation</strong> ensures that any flow entering a node must be 
      distributed among its outgoing edges. A molecule with a higher “reward” (for instance, a better prediction 
      for binding to a target protein) naturally receives more flow. This means GFlowNets are not locked onto 
      one single candidate; they encourage multiple promising solutions. That diversity can be crucial when 
      searching large spaces, such as all possible molecules you might want to synthesize and test.
    </p>
    
    <!-- BIG DAG in #moleculeFlowSVG (molecule_flow.js) -->
    <div id="moleculeFlowContainer">
      <svg id="moleculeFlowSVG" width="1000" height="600"></svg>
      <div
        id="flowTooltipBig"
        style="position:absolute; background:#333; color:#fff; padding:6px;
               border-radius:4px; pointer-events:none; opacity:0;"
      >
      </div>
    </div>

    <style>
      #moleculeFlowContainer {
        max-width: 1000px;
        margin: 0 auto;
        padding: 0;
        text-align: center;
      }

      #moleculeFlowSVG {
        display: block;
        margin: 0 auto;
      }
    </style>

    <script src="static/molecule_flow.js"></script>
    <script>
      document.addEventListener("DOMContentLoaded", function() {
        initMoleculeFlowDemo();
      });
    </script>

    <details>
      <summary>Interpreting the DAG</summary>
      <p>
        Each row or level in this visualization shows more advanced forms of the 
        partial molecule. Nodes represent the current state of the molecule, 
        and edges represent choices you can make at that step (such as adding a 
        chemical group). Multiple paths can merge into the same node if there are 
        different ways to reach the same structure. The terminal state is the reward on 
        how good the molecules properties are based on the reward function. In this DAG the three terminal states on top are the candidate solutions, 
        whereas the bottom three terminal states are solutions that the GFlowNet assigns less reward. 
      </p>
    </details>

    <details>
      <summary>Why This Matters in Drug Discovery</summary>
      <p>
        Drug discovery involves exploring many possible molecular structures 
        in hopes of finding effective treatments. Because GFlowNets distribute 
        “flow” across a set of strong candidates, they can systematically 
        uncover molecules with good properties without missing other viable options. 
        If a top molecule fails in real testing, the method still has other strong 
        candidates to propose.      </p>
      <p>
        This ability to handle uncertainty in scoring (for example, uncertain predictions 
        of how well a molecule binds) makes GFlowNets a powerful tool. Instead of discarding 
        lower-scoring molecules outright, some flow will still reach them, keeping 
        potential alternatives in play. Moreover, scientists also obtain samples with lower rewards, which can further enhance their understanding of the molecule generation process using GFlowNets. 

      </p>
    </details>

    <details>
      <summary>Technical Insight: Flow = Reward at Terminal Nodes</summary>
      <p>
        When the DAG reaches a terminal node that represents a complete molecule, 
        the amount of flow arriving there matches the reward for that molecule. 
        This ensures that the fraction of flow allocated to each final structure 
        aligns with how promising that molecule is, based on the reward function. 
        Training a GFlowNet involves adjusting these flows so that the final 
        distribution over molecules reflects their rewards.
      </p>
    </details>

    <details>
      <summary>BONUS: Pretraining GFlowNets for Fast Inference</summary>
      <p>
        One of the key benefits of GFlowNets is that they can be pretrained. 
        You spend the computation time upfront, and once the network has learned, 
        it can produce diverse, high-quality candidates almost instantly. This 
        speeds up tasks like generating large batches of promising molecules 
        during the exploration phase of drug development.
      </p>
      <p>
        Compared to traditional methods that require extensive searching for each new design, 
        a pretrained GFlowNet quickly provides a broad set of potentially strong solutions 
        without repeated heavy computations.
      </p>
    </details>

    <div class="references">
      <h3>Further Reading – Core Concepts & Flow Conservation</h3>
      <ul>
        <li>
          <strong>[1]</strong>
          Malkin, N. et al.
          <a href="https://arxiv.org/pdf/2201.13259.pdf" target="_blank">
            <em>Trajectory Balance: Improved Credit Assignment in GFlowNets</em>
          </a>
          (ICML 2022)
        </li>
        <li>
          <strong>[2]</strong>
          Madan, K. et al.
          <a href="https://arxiv.org/pdf/2209.12782.pdf" target="_blank">
            <em>Learning GFlowNets from Partial Episodes for Improved Convergence and Stability</em>
          </a>
          (arXiv 2022)
        </li>
      </ul>
    </div>

  </div>
</section>

<section id="advanced-math">
  <div class="section-content">
    <h2>5. Advanced Math</h2>
    <p>
      Below are expansions with more formal definitions, training objectives like 
      Trajectory Balance, Flow Matching, Detailed Balance and references to the 
      original derivations. Expand any if you want the rigorous details.
    </p>

    <!-- Flow Formulas & Probability Calculation -->
    <details>
      <summary>Flow Formulas &amp; Probability Calculation</summary>
      <p>
        Let $F(s \to s')$ be the flow from state $s$ to state $s'$.  
        In a non-terminal state $s$:
      </p>
      <!-- Display mode equation with double $$ -->
      $$\sum_{\text{children of } s} F\bigl(s \to s_{\text{child}}\bigr) 
        \;=\; 
        \sum_{\text{parents of } s} F\bigl(s_{\text{parent}} \to s\bigr).$$

      <p>
        For a terminal state $x$, the total inflow equals its reward:  
        $$\sum_{\text{parents of } x} F(\ldots) \;=\; R(x).$$
        Sampling $x$ with probability 
        $$\frac{R(x)}{\sum R(x')}$$ 
        follows if we treat each $F(s \to s')$ as unnormalized probabilities 
        forming a policy.
      </p>
    </details>

    <!-- Trajectory Balance (TB) -->
    <details>
      <summary>Trajectory Balance (TB)</summary>
      <p>
        TB ties the forward probabilities along a trajectory to the reward $R(x)$ 
        and the backward probabilities. Specifically, if  
        $$\tau = (s_0 \to s_1 \to \dots \to s_n = x)$$
        is a path to terminal $x$, TB wants:
      </p>
      $$\frac{P_F(\tau)}{Q(\tau)} \;=\; \frac{R(x)}{Z},$$

      <p>
        where $Q(\tau)$ is the backward or reverse path probability and $Z$ 
        is the partition function (the sum of all $R(x)$).  
        This elegantly ensures each trajectory’s total probability mass 
        aligns with the reward.
      </p>
    </details>

    <!-- Flow Matching & Detailed Balance -->
    <details>
      <summary>Flow Matching &amp; Detailed Balance</summary>
      <p>
        Flow Matching is a local constraint approach: for each state $s$, 
        <em>incoming flow = outgoing flow</em>. Detailed Balance is a pairwise 
        condition that ensures symmetrical consistency across edges, also leading 
        to a consistent overall distribution.
      </p>
      <p>
        Both yield solutions that sample final states in proportion to $R(x)$, but 
        TB can handle longer trajectories more effectively, often reducing variance.
      </p>
    </details>

    <!-- References -->
    <div class="references">
      <h3>Further Reading – Advanced Math</h3>
      <ul>
        <li>
          <strong>[1]</strong>
          Zimmermann, H. et al.
          <a href="https://arxiv.org/pdf/2210.07992.pdf" target="_blank">
            <em>A Variational Perspective on Generative Flow Networks</em>
          </a>
          (arXiv 2022)
        </li>
        <li>
          <strong>[2]</strong>
          Jiralerspong, M. et al.
          <a href="https://arxiv.org/pdf/2310.02779.pdf" target="_blank">
            <em>Expected Flow Networks in Stochastic Environments and Two-Player Zero-Sum Games</em>
          </a>
          (arXiv 2023)
        </li>
        <li>
          <strong>[3]</strong>
          Li, C. et al.
          <a href="https://arxiv.org/pdf/2406.01901.pdf" target="_blank">
            <em>Bifurcated Generative Flow Networks</em>
          </a>
          (arXiv 2024)
        </li>
      </ul>
    </div>
    
</section>

  
</main>

<!-- (Line 830) FOOTER -->
<footer>
  <p>&copy; 2025 – Understanding Generative Flow Networks (GFlowNets) - A User perspective</p>
</footer>

<script src="https://cdn.jsdelivr.net/npm/particles.js@2.0.0/particles.min.js"></script>
<script src="https://d3js.org/d3.v7.min.js"></script>
<script src="https://unpkg.com/d3-sankey@0.12.3/dist/d3-sankey.min.js"></script>


<script>

"use strict";


// ====================== CONSTANTS & GLOBALS ======================
const CELL_SIZE = 30;
const COLS = 10;
const ROWS = 20;
const TICK_INTERVAL = 700;
const MOVE_PAUSE_DURATION = 2000;

// Game/Agent
let game = null;
let agent = null;    // We'll keep this for the old TrajectoryBalanceAgent
let nnModel = null;  // This is our new big MLP model
let trajectory = [];

// UI Elements
let canvas = null;
let ctx = null;
let candidateListEl = null;
let resetBtn = null;

// State
let currentGameState = null;
let currentPieceCenter = { x:0, y:0 };
let candidateMoves = [];
let topCandidates = [];
let appliedArrows = [];
let particles = [];

let simulationPaused = false;
let lastPieceId = null;
let particleSpawnAccumulator = 0;
let lastTime = performance.now();

// ====================== TETROMINO DEFINITIONS ======================
const TETROMINOES = {
  I: [
    [0,0,0,0],
    [1,1,1,1],
    [0,0,0,0],
    [0,0,0,0]
  ],
  O: [
    [1,1],
    [1,1]
  ],
  T: [
    [0,1,0],
    [1,1,1],
    [0,0,0]
  ],
  S: [
    [0,1,1],
    [1,1,0],
    [0,0,0]
  ],
  Z: [
    [1,1,0],
    [0,1,1],
    [0,0,0]
  ],
  J: [
    [1,0,0],
    [1,1,1],
    [0,0,0]
  ],
  L: [
    [0,0,1],
    [1,1,1],
    [0,0,0]
  ]
};
const PIECES = Object.keys(TETROMINOES);
const PIECE_IDS = {};
PIECES.forEach((p,i)=> { PIECE_IDS[p] = i; });

// ====================== HELPER FUNCTIONS ======================
function deepCopy(matrix) {
  return JSON.parse(JSON.stringify(matrix));
}
function rotateMatrix(matrix) {
  const rows = matrix.length;
  const cols = matrix[0].length;
  const rotated = [];
  for (let c=0; c<cols; c++){
    rotated[c] = [];
    for (let r=rows-1; r>=0; r--){
      rotated[c].push(matrix[r][c]);
    }
  }
  return rotated;
}
function hexToRgb(hex) {
  hex = hex.replace(/^#/, "");
  const bigint = parseInt(hex, 16);
  return {
    r: (bigint >> 16) & 255,
    g: (bigint >> 8) & 255,
    b: bigint & 255
  };
}

// ====================== TETRIS GAME CLASS ======================
class TetrisGame {
  constructor(cols=COLS, rows=ROWS){
    this.cols = cols;
    this.rows = rows;
    this.reset_game();
  }
  reset_game(){
    this.board = [];
    for(let r=0; r<this.rows; r++){
      this.board.push(new Array(this.cols).fill(0));
    }
    this.score = 0;
    this.game_over = false;
    this.piece_id = 0;
    this.current_piece = this.spawn_piece();
    this.target_piece = null;
    this.cached_moves = null;
    this._cached_state_key = null;
  }
  spawn_piece(){
    this.piece_id += 1;
    const tTypes = Object.keys(TETROMINOES);
    const t_type = tTypes[Math.floor(Math.random()*tTypes.length)];
    const shape = deepCopy(TETROMINOES[t_type]);
    const piece = {
      type: t_type,
      shape: shape,
      x: Math.floor((this.cols - shape[0].length)/2),
      y: 0
    };
    // check collision
    if(this.collides(piece)){
      this.game_over = true;
    }
    return piece;
  }
  collides(piece){
    const shape = piece.shape;
    for(let r=0; r<shape.length; r++){
      for(let c=0; c<shape[r].length; c++){
        if(shape[r][c]){
          const x = piece.x+c;
          const y = piece.y+r;
          if(x<0 || x>=this.cols || y>=this.rows){
            return true;
          }
          if(y>=0 && this.board[y][x]){
            return true;
          }
        }
      }
    }
    return false;
  }
  clear_lines(){
    const new_board = [];
    for(let r=0; r<this.board.length; r++){
      if(!this.board[r].every(cell => cell===1)){
        new_board.push(this.board[r]);
      }
    }
    const cleared = this.rows - new_board.length;
    for(let i=0; i<cleared; i++){
      new_board.unshift(new Array(this.cols).fill(0));
    }
    this.board = new_board;
    this.score += cleared;
    return cleared;
  }
  lock_piece(){
    const p = this.current_piece;
    for(let r=0; r<p.shape.length; r++){
      for(let c=0; c<p.shape[r].length; c++){
        if(p.shape[r][c]){
          const x = p.x + c;
          const y = p.y + r;
          if(x>=0 && x<this.cols && y>=0 && y<this.rows){
            this.board[y][x] = 1;
          }
        }
      }
    }
    this.clear_lines();
    this.current_piece = this.spawn_piece();
    this.target_piece = null;
    this.cached_moves = null;
    this._cached_state_key = null;
  }
  lock_target(){
    if(!this.target_piece) return;
    const p = this.target_piece;
    for(let r=0; r<p.shape.length; r++){
      for(let c=0; c<p.shape[r].length; c++){
        if(p.shape[r][c]){
          const x = p.x + c;
          const y = p.y + r;
          if(x>=0 && x<this.cols && y>=0 && y<this.rows){
            this.board[y][x] = 1;
          }
        }
      }
    }
    this.clear_lines();
    this.current_piece = this.spawn_piece();
    this.target_piece = null;
    this.cached_moves = null;
    this._cached_state_key = null;
  }
  get_piece_center(piece=null){
    if(!piece) piece = this.current_piece;
    if(!piece || !piece.shape) return { x:0, y:0 };
    const h = piece.shape.length;
    const w = piece.shape[0].length;
    return {
      x: (piece.x + w/2)*CELL_SIZE,
      y: (piece.y + h/2)*CELL_SIZE
    };
  }
  get_state_key(){
    const piece = this.current_piece;
    const stateObj = {
      board: this.board,
      piece: {
        type: piece.type,
        shape: piece.shape,
        x: piece.x,
        y: piece.y
      }
    };
    return JSON.stringify(stateObj);
  }
  get_terminal_moves(){
    if(this.game_over){
      return [];
    }
    const current_state_key = this.get_state_key();
    if(this.cached_moves && this._cached_state_key===current_state_key){
      return this.cached_moves;
    }
    const orig = this.current_piece;
    const base_shape = TETROMINOES[orig.type];
    const candidates = [];
    const rotations = (orig.type==="O") ? [0] : [0,1,2,3];
    for(let rot of rotations){
      let shape = deepCopy(base_shape);
      for(let i=0; i<rot; i++){
        shape = rotateMatrix(shape);
      }
      const w = shape[0].length;
      for(let x=0; x<=this.cols-w; x++){
        const testPiece = {
          type: orig.type,
          shape: deepCopy(shape),
          x: x,
          y: 0
        };
        if(this.collides(testPiece)){
          continue;
        }
        let y=0;
        while(!this.collides({...testPiece, y:y}) && y<this.rows){
          y++;
        }
        testPiece.y = y-1;
        if(testPiece.y<0) continue;
        const center = this.get_piece_center(testPiece);
        const action_key = `r${rot}_x${x}`;
        candidates.push({
          action_key: action_key,
          piece: testPiece,
          piece_center: center
        });
      }
    }
    this.cached_moves = candidates;
    this._cached_state_key = current_state_key;
    return candidates;
  }
  tick(){
    if(this.game_over) return;
    if(this.target_piece){
      this.current_piece.shape = deepCopy(this.target_piece.shape);
      this.cached_moves = null;
      this._cached_state_key = null;
      const px = this.current_piece.x;
      const py = this.current_piece.y;
      const tx = this.target_piece.x;
      const ty = this.target_piece.y;
      if(px<tx) this.current_piece.x++;
      else if(px>tx) this.current_piece.x--;
      if(py<ty) this.current_piece.y++;
      else if(py>ty) this.current_piece.y--;
      if(this.current_piece.x===tx && this.current_piece.y===ty){
        this.lock_target();
      }
    } else {
      const nextP = {
        type: this.current_piece.type,
        shape: this.current_piece.shape,
        x: this.current_piece.x,
        y: this.current_piece.y+1
      };
      if(!this.collides(nextP)){
        this.current_piece.y++;
      } else {
        this.lock_piece();
      }
    }
  }
  is_over(){
    return this.game_over;
  }
  get_final_reward(){
    if(this.game_over){
      return this.score*10 - 10;
    } else {
      return this.score*10;
    }
  }
}

// ====================== TRAJECTORY BALANCE AGENT (old) ======================
class TrajectoryBalanceAgent {
  constructor(lr=0.01){
    this.log_flows = {};
    this.logZ = 0.0;
    this.lr = lr;
  }
  _ensure_action_exists(state_key, action_key){
    if(!this.log_flows[state_key]){
      this.log_flows[state_key] = {};
    }
    if(!this.log_flows[state_key][action_key]){
      const val = 0.5 + Math.random();
      this.log_flows[state_key][action_key] = Math.log(val);
    }
  }
  sample_action(state_key, candidates){
    for(let c of candidates){
      this._ensure_action_exists(state_key, c.action_key);
    }
    const logValues = candidates.map(c => this.log_flows[state_key][c.action_key]);
    const max_log = Math.max(...logValues);
    const exps = logValues.map(lv => Math.exp(lv - max_log));
    const sum_exps = exps.reduce((a,b)=>a+b,0);
    const probs = exps.map(e=> e/sum_exps);
    const r = Math.random();
    let cum=0, idx=0;
    for(let i=0; i<probs.length; i++){
      cum += probs[i];
      if(r<=cum){
        idx=i; break;
      }
    }
    return [candidates[idx], probs[idx]];
  }
  get_log_p_action(state_key, action_key){
    this._ensure_action_exists(state_key, action_key);
    const all_logs = Object.values(this.log_flows[state_key]);
    const max_val = Math.max(...all_logs);
    const sum_exp = all_logs.reduce((acc,x)=> acc+Math.exp(x - max_val), 0);
    const denom = Math.log(sum_exp)+max_val;
    const numerator = this.log_flows[state_key][action_key];
    return numerator - denom;
  }
  update_trajectory(traj, final_reward){
    if(final_reward<=0) final_reward=0.01;
    const logR = Math.log(final_reward);
    let sum_logp=0;
    for(let [s,a] of traj){
      sum_logp += this.get_log_p_action(s,a);
    }
    const target = logR - this.logZ;
    const diff = sum_logp - target;
    // update logZ
    this.logZ += this.lr*diff;
    // update flows
    for(let [s,a] of traj){
      this.log_flows[s][a] -= this.lr*diff;
    }
  }
  loadFromJSON(obj){
    try {
      this.log_flows = obj.log_flows || obj.weights || {};
      this.logZ = obj.logZ || 0.0;
      console.log("[agent] Loaded from JSON. (#states=", 
          Object.keys(this.log_flows).length, ", logZ=", this.logZ, ")");
    } catch(e){
      console.error("[agent] Error loading from JSON:", e);
    }
  }
}

// ====================== NEURAL NET REPLACEMENT ======================
// We'll load "pretrained_flows_nn.json" => with a big MLP (3 hidden layers).
// We'll define a class that does forward pass: input => 214 dims => output => logFlow(s,a).
// This matches the Python code that has state(212) + action(2) => 214 total.
class NeuralFlowNet {
  constructor(){
    this.logZ= 0.0;
    this.loaded= false;
    // We'll store the named params:
    // net.0.weight => shape [512, 214]
    // net.0.bias   => shape [512]
    // net.2.weight => shape [512,512]
    // net.2.bias   => shape [512]
    // net.4.weight => shape [512,512]
    // net.4.bias   => shape [512]
    // net.6.weight => shape [1,512]
    // net.6.bias   => shape [1]
    this.W0=null; this.b0=null;
    this.W2=null; this.b2=null;
    this.W4=null; this.b4=null;
    this.W6=null; this.b6=null;
  }
  loadJson(obj){
    this.logZ= obj.logZ || 0.0;
    let w= obj.weights;
    this.W0= w["net.0.weight"];
    this.b0= w["net.0.bias"];
    this.W2= w["net.2.weight"];
    this.b2= w["net.2.bias"];
    this.W4= w["net.4.weight"];
    this.b4= w["net.4.bias"];
    this.W6= w["net.6.weight"];
    this.b6= w["net.6.bias"];
    this.loaded= true;
    console.log("[NeuralFlowNet] loaded. logZ=", this.logZ);
  }
  // matrix vector multiply
  static matvec(W, x){
    let rows= W.length;
    let out= new Array(rows).fill(0);
    for (let r=0; r<rows; r++){
      let sum=0;
      let row= W[r];
      for (let c=0; c<row.length; c++){
        sum+= row[c]* x[c];
      }
      out[r]= sum;
    }
    return out;
  }
  forward(x214){
    // layer0
    let z0= NeuralFlowNet.matvec(this.W0, x214);
    for (let i=0; i<z0.length; i++){
      z0[i]+= this.b0[i];
      if (z0[i]<0) z0[i]=0; // ReLU
    }
    // layer2
    let z2= NeuralFlowNet.matvec(this.W2, z0);
    for (let i=0; i<z2.length; i++){
      z2[i]+= this.b2[i];
      if (z2[i]<0) z2[i]=0;
    }
    // layer4
    let z4= NeuralFlowNet.matvec(this.W4, z2);
    for (let i=0; i<z4.length; i++){
      z4[i]+= this.b4[i];
      if (z4[i]<0) z4[i]=0;
    }
    // layer6 => output => shape [1]
    let z6= NeuralFlowNet.matvec(this.W6, z4);
    let out= z6[0] + this.b6[0];
    return out; // logFlow
  }
}

// We'll define the encodeStateAction => 214 dims
// board => 20*10=200
// pieceOneHot =>7
// piece x,y =>2
// some heuristics => let's do holes, maxH, bump => 3 => total=212 for state
// plus action =>2 => total=214
function flattenBoard(board){
  // 20 x10 =>200
  let arr=[];
  for (let r=0; r<board.length; r++){
    arr.push(...board[r]);
  }
  return arr;
}
function countHoles(board){
  let holes=0;
  let rows= board.length;
  let cols= board[0].length;
  for (let c=0; c<cols; c++){
    let blockFound=false;
    for (let r=0; r<rows; r++){
      if (board[r][c]===1) {
        blockFound=true;
      } else if (blockFound && board[r][c]===0){
        holes++;
      }
    }
  }
  return holes;
}
function boardMaxHeight(board){
  let rows= board.length;
  for (let r=0; r<rows; r++){
    if (board[r].some(cell=>cell===1)){
      return rows-r;
    }
  }
  return 0;
}
function countBumpiness(board){
  let rows= board.length;
  let cols= board[0].length;
  let heights=[];
  for (let c=0;c<cols;c++){
    let h=0;
    for (let r=0;r<rows;r++){
      if (board[r][c]===1){
        h= rows-r;
        break;
      }
    }
    heights.push(h);
  }
  let bump=0;
  for (let c=0;c<cols-1;c++){
    bump+= Math.abs(heights[c]- heights[c+1]);
  }
  return bump;
}
function encodeState(board, piece){
  // flatten =>200
  let flat= flattenBoard(board);
  // pieceOneHot =>7
  let oh= new Array(7).fill(0);
  let idx= PIECE_IDS[piece.type] || 0;
  oh[idx]=1;
  // piece coords =>2 => normalized
  let px= piece.x/(COLS-1);
  let py= piece.y/(ROWS-1);
  // heuristics => holes, maxH, bump =>3
  let holes= countHoles(board);
  let maxH= boardMaxHeight(board);
  let bump= countBumpiness(board);
  let features= flat.concat( oh, [px,py], [holes,maxH,bump] );
  return features; // length=212
}
function encodeAction(aKey){
  // "r2_x3" => parse => rVal =>2/3, xVal=>3/(COLS-1)
  let [rPart,xPart]= aKey.split("_"); // e.g. "r2","x3"
  let rotStr= rPart.slice(1); // "2"
  let xStr= xPart.slice(1);   // "3"
  let rVal= parseInt(rotStr)/3.0;
  let xVal= parseInt(xStr)/(COLS-1);
  return [rVal,xVal]; // length=2
}
function encodeStateAction(board, piece, actionKey){
  let st= encodeState(board, piece); // 212
  let ac= encodeAction(actionKey);   // 2
  return st.concat(ac); // 214
}

// ====================== VISUAL EFFECTS ======================
class Particle {
  constructor(x,y,vx,vy,radius=4,life=1.0,color={r:255,g:255,b:255}){
    this.x=x; this.y=y; this.vx=vx; this.vy=vy;
    this.radius=radius; this.life=life; this.color=color;
  }
  update(dt){
    this.x += this.vx*dt;
    this.y += this.vy*dt;
    this.life -= dt*0.4;
  }
  draw(ctx){
    ctx.beginPath();
    ctx.arc(this.x,this.y,this.radius,0,2*Math.PI);
    let grad=ctx.createRadialGradient(this.x,this.y,this.radius/2,this.x,this.y,this.radius);
    grad.addColorStop(0,`rgba(${this.color.r},${this.color.g},${this.color.b},${this.life})`);
    grad.addColorStop(1,`rgba(${this.color.r},${this.color.g},${this.color.b},0)`);
    ctx.fillStyle=grad;
    ctx.fill();
  }
}
class Arrow {
  constructor(from,to,flow,color="#66ff66"){
    this.from=from; this.to=to; this.flow=flow; this.color=color;
    this.life=1.0;
  }
  update(dt){
    this.life -= dt*0.5;
  }
  draw(ctx){
    const rgb=hexToRgb(this.color);
   // let lineWidth = Math.min(10, 2+this.flow/2000);
    ctx.strokeStyle=`rgba(${rgb.r},${rgb.g},${rgb.b},${0.8*this.life})`;
    // ctx.lineWidth=lineWidth;
    ctx.beginPath();
    ctx.moveTo(this.from.x,this.from.y);
    ctx.lineTo(this.to.x,this.to.y);
    ctx.stroke();
    let angle=Math.atan2(this.to.y - this.from.y,this.to.x - this.from.x);
    ctx.beginPath();
    ctx.moveTo(this.to.x,this.to.y);
    ctx.lineTo(this.to.x - 10*Math.cos(angle - Math.PI/6),
               this.to.y - 10*Math.sin(angle - Math.PI/6));
    ctx.lineTo(this.to.x - 10*Math.cos(angle + Math.PI/6),
               this.to.y - 10*Math.sin(angle + Math.PI/6));
    ctx.closePath();
    ctx.fillStyle=`rgba(${rgb.r},${rgb.g},${rgb.b},${0.8*this.life})`;
    ctx.fill();
  }
}

// ====================== "API" LOGIC (FRONT-END) ======================
function getCandidateMoves(){
  if(game.is_over()){
    return {
      current_piece_center: game.get_piece_center(),
      terminal_moves: [],
      game_state: {
        board: game.board,
        current_piece: game.current_piece,
        score: game.score,
        game_over: game.game_over
      }
    };
  }
  const cands = game.get_terminal_moves();
  const result=[];
  // If neural net is loaded, we'll compute logFlow => flow => prob
  // Otherwise, we fallback to the old "agent" table or random
  if(nnModel && nnModel.loaded){
    let sumFlow=0;
    for(let c of cands){
      let sa= encodeStateAction(game.board, game.current_piece, c.action_key);
      let logF= nnModel.forward(sa);
      // clamp to avoid overflow
      if(logF>20) logF=20;
      if(logF<-20) logF=-20;
      let flow= Math.exp(logF);
      c.flow=flow;
      sumFlow+= flow;
    }
    for(let c of cands){
      c.probability= (sumFlow>0) ? (c.flow/sumFlow) : (1.0/cands.length);
      result.push(c);
    }
  } else {
    // fallback => like the old approach with agent
    const state_key = game.get_state_key();
    let sum_exp=0;
    for(let c of cands){
      agent._ensure_action_exists(state_key,c.action_key);
      const val=Math.exp(agent.log_flows[state_key][c.action_key]);
      sum_exp += val;
    }
    for(let c of cands){
      const flow_val=Math.exp(agent.log_flows[state_key][c.action_key]);
      const prob = (sum_exp>0)? flow_val/sum_exp : (1.0/cands.length);
      c.flow=flow_val; 
      c.probability=prob;
      result.push(c);
    }
  }
  return {
    current_piece_center: game.get_piece_center(),
    terminal_moves: result,
    game_state: {
      board: game.board,
      current_piece: game.current_piece,
      score: game.score,
      game_over: game.game_over
    }
  };
}

function selectMove(actionKey=null){
  if(game.is_over()){
    return { error:"Game Over" };
  }
  const cands = game.get_terminal_moves();
  if(!cands || cands.length===0){
    return { error:"No moves" };
  }
  let selected_action=null;
  if(actionKey){
    selected_action = cands.find(x=>x.action_key===actionKey) || null;
  }
  if(!selected_action){
    // auto pick the top candidate if using NN => best flow
    if(nnModel && nnModel.loaded){
      // pick candidate with the highest c.flow
      cands.sort((a,b)=> (b.flow||0) - (a.flow||0));
      selected_action= cands[0];
    } else {
      // fallback => sample from old agent
      const state_key = game.get_state_key();
      const [cand,_p] = agent.sample_action(state_key, cands);
      selected_action=cand;
    }
  }
  trajectory.push([game.get_state_key(), selected_action.action_key]);
  game.target_piece = deepCopy(selected_action.piece);
  const arrow_info={
    from: game.get_piece_center(game.current_piece),
    to: selected_action.piece_center,
    flow: selected_action.flow||0,
    probability: selected_action.probability||0
  };
  return {
    action_key: selected_action.action_key,
    arrow: arrow_info,
    game_state:{
      board: game.board,
      current_piece: game.current_piece,
      score: game.score,
      game_over: game.game_over,
      piece_id: game.piece_id
    }
  };
}
function tickGameLogic(){
  const old_go=game.is_over();
  const old_pid=game.piece_id;
  game.tick();
  const new_go=game.is_over();
  const new_pid=game.piece_id;
  if(new_go && !old_go){
    const final_reward=game.get_final_reward();
    agent.update_trajectory(trajectory, final_reward);
    trajectory=[];
    game.reset_game();
  }
  let terminal_moves=[];
  if(new_pid!==old_pid && !game.is_over()){
    const cands= game.get_terminal_moves();
    if(nnModel && nnModel.loaded){
      let sumFlow=0;
      for(let c of cands){
        let sa= encodeStateAction(game.board, game.current_piece, c.action_key);
        let logF= nnModel.forward(sa);
        if(logF>20) logF=20;
        if(logF<-20) logF=-20;
        let fv= Math.exp(logF);
        c.flow= fv;
        sumFlow+= fv;
      }
      for(let c of cands){
        c.probability= sumFlow>0 ? (c.flow/sumFlow) : (1.0/cands.length);
        terminal_moves.push(c);
      }
    } else {
      // fallback => old agent
      const state_key= game.get_state_key();
      let sum_exp=0;
      for(let c of cands){
        agent._ensure_action_exists(state_key,c.action_key);
        sum_exp+= Math.exp(agent.log_flows[state_key][c.action_key]);
      }
      for(let c of cands){
        const fv=Math.exp(agent.log_flows[state_key][c.action_key]);
        const prob = sum_exp>0 ? fv/sum_exp : (1.0/cands.length);
        c.flow=fv; 
        c.probability=prob;
        terminal_moves.push(c);
      }
    }
  }
  return {
    game_state:{
      board: game.board,
      current_piece: game.current_piece,
      score: game.score,
      game_over: game.game_over,
      piece_id: game.piece_id
    },
    current_piece_center: game.get_piece_center(),
    terminal_moves: terminal_moves
  };
}
function resetGameLogic(){
  game.reset_game();
  trajectory=[];
  return {status:"reset"};
}

// ====================== UI & ANIMATION ======================
function assignCandidateColors(candidates){
  candidates.forEach((cand,i)=>{
    if(i===0) cand.color="#33ff66";
    else if(i===1) cand.color="#ffd700";
    else if(i===2) cand.color="#ff6666";
    else cand.color="#dddddd";
  });
}
function drawBoard(gs){
  ctx.clearRect(0,0,canvas.width,canvas.height);
  ctx.fillStyle="#222";
  ctx.fillRect(0,0,canvas.width,canvas.height);
  if(!gs||!gs.board) return;
  for(let r=0; r<ROWS; r++){
    for(let c=0; c<COLS; c++){
      if(gs.board[r][c]){
        ctx.fillStyle="#666";
        ctx.fillRect(c*CELL_SIZE,r*CELL_SIZE,CELL_SIZE,CELL_SIZE);
        ctx.strokeStyle="#444";
        ctx.strokeRect(c*CELL_SIZE,r*CELL_SIZE,CELL_SIZE,CELL_SIZE);
      } else {
        ctx.strokeStyle="rgba(255,255,255,0.05)";
        ctx.strokeRect(c*CELL_SIZE,r*CELL_SIZE,CELL_SIZE,CELL_SIZE);
      }
    }
  }
}
function drawCurrentPiece(gs){
  if(!gs||!gs.current_piece) return;
  const piece = gs.current_piece;
  let grad=ctx.createLinearGradient(0,0,0,piece.shape.length*CELL_SIZE);
  grad.addColorStop(0,"#c0c0c0");
  grad.addColorStop(1,"#a0a0a0");
  ctx.fillStyle=grad;
  for(let r=0; r<piece.shape.length; r++){
    for(let c=0; c<piece.shape[r].length; c++){
      if(piece.shape[r][c]){
        const x=(piece.x+c)*CELL_SIZE;
        const y=(piece.y+r)*CELL_SIZE;
        ctx.fillRect(x,y,CELL_SIZE,CELL_SIZE);
        ctx.strokeStyle="#888";
        ctx.strokeRect(x,y,CELL_SIZE,CELL_SIZE);
      }
    }
  }
}
function drawCandidateShadow(piece,color){
  if(!piece||!piece.shape)return;
  ctx.save();
  const rgb=hexToRgb(color||"#fff");
  ctx.fillStyle=`rgba(${rgb.r},${rgb.g},${rgb.b},0.2)`;
  for(let r=0; r<piece.shape.length; r++){
    for(let c=0; c<piece.shape[r].length; c++){
      if(piece.shape[r][c]){
        const x=(piece.x+c)*CELL_SIZE;
        const y=(piece.y+r)*CELL_SIZE;
        ctx.fillRect(x,y,CELL_SIZE,CELL_SIZE);
      }
    }
  }
  ctx.restore();
}
function spawnParticles(from,to,factor=1,color){
  let count=Math.max(1,Math.round(7*factor));
  let dx=to.x-from.x;
  let dy=to.y-from.y;
  let dist=Math.hypot(dx,dy)||1;
  let ux=dx/dist;
  let uy=dy/dist;
  let baseColor=color?hexToRgb(color):{r:255,g:255,b:255};
  for(let i=0; i<count; i++){
    const t=Math.random();
    const x=from.x+dx*t;
    const y=from.y+dy*t;
    let speed=30+Math.random()*20;
    let vx=ux*speed+(Math.random()-0.5)*10;
    let vy=uy*speed+(Math.random()-0.5)*10;
    particles.push(new Particle(x,y,vx,vy,4,1.0,baseColor));
  }
}
function spawnArrow(from,to,flow,color){
  appliedArrows.push(new Arrow(from,to,flow,color));
}
function drawEffects(){
  appliedArrows.forEach(a=>a.draw(ctx));
  particles.forEach(p=>p.draw(ctx));
}
function draw(){
  drawBoard(currentGameState);
  drawCurrentPiece(currentGameState);
  topCandidates.forEach(c=>{
    let arr=new Arrow(currentPieceCenter,c.piece_center,c.flow,c.color);
    arr.draw(ctx);
    drawCandidateShadow(c.piece,c.color);
  });
  drawEffects();
}
function animate(){
  let now=performance.now();
  let dt=(now - lastTime)/1000;
  lastTime=now;

  particleSpawnAccumulator+=dt;
  if(particleSpawnAccumulator>0.25){
    if(topCandidates.length>0){
      let maxFlow=topCandidates[0].flow||1;
      topCandidates.forEach((cand,i)=>{
        let ratio=cand.flow/maxFlow;
        if(i===0) ratio*=3;
        else if(i===1) ratio*=1.5;
        else if(i===2) ratio*=0.5;
        spawnParticles(currentPieceCenter,cand.piece_center,ratio,cand.color);
      });
    }
    particleSpawnAccumulator=0;
  }

  for(let i=particles.length-1; i>=0; i--){
    particles[i].update(dt);
    if(particles[i].life<=0){
      particles.splice(i,1);
    }
  }
  appliedArrows.forEach(a=>a.update(dt));
  draw();
  requestAnimationFrame(animate);
}

// ====================== FRONT-END "ENDPOINTS" ======================
function fetchCandidateMoves(){
  if (simulationPaused) return;
  const data = getCandidateMoves();
  currentGameState = data.game_state || {};
  currentPieceCenter = data.current_piece_center || {x:0,y:0};
  candidateMoves = data.terminal_moves || [];
  // if empty => done
  if (!candidateMoves.length){
    topCandidates=[];
    updateCandidateListUI();
    return;
  }

  // 1) Sort or find max
  candidateMoves.sort((a,b)=>(b.flow||0) - (a.flow||0));
  let maxFlowVal = candidateMoves[0].flow || 1;
  // 2) Normalize each flow by dividing by that max
  candidateMoves.forEach(c=>{
    c.flowNormalized = c.flow / maxFlowVal; 
  });
  // 3) Possibly multiply by some factor, e.g. 100, to display as small integers
  candidateMoves.forEach(c=>{
    c.flowDisplay = (c.flowNormalized * 100).toFixed(2);
  });

  // We'll keep flow for probability, but for display use c.flowDisplay
  topCandidates = candidateMoves.slice(0,3);
  assignCandidateColors(topCandidates);
  updateCandidateListUI();

  // auto-select top
  const firstCandidateEl = candidateListEl.querySelector(".candidate");
  if(firstCandidateEl){
    firstCandidateEl.click();
  }
}

function doSelectCandidate(actionKey){
  simulationPaused=true;
  const data = selectMove(actionKey);
  if(data.error){
    console.error("[doSelectCandidate] error:", data.error);
    simulationPaused=false;
    return;
  }
  if(data.arrow){
    let arrowData=data.arrow;
    let cand=topCandidates.find(c=>
      Math.abs(c.piece_center.x - arrowData.to.x)<1 &&
      Math.abs(c.piece_center.y - arrowData.to.y)<1
    );
    let color=cand?cand.color:"#33ff66";
    spawnArrow(arrowData.from, arrowData.to, arrowData.flow, color);
  }
  currentGameState=data.game_state||{};
  setTimeout(()=>{ simulationPaused=false; }, MOVE_PAUSE_DURATION);
}
function tickGame(){
  if(!simulationPaused){
    const data=tickGameLogic();
    currentGameState=data.game_state||{};
    currentPieceCenter=data.current_piece_center||{x:0,y:0};
    const newPieceId=currentGameState.piece_id;
    if(typeof newPieceId!=="undefined" && newPieceId!==lastPieceId){
      lastPieceId=newPieceId;
      setTimeout(fetchCandidateMoves,200);
    }
  }
}
function doResetGame(){
  resetGameLogic();
  currentGameState=null;
  currentPieceCenter={x:0,y:0};
  candidateMoves=[];
  topCandidates=[];
  appliedArrows=[];
  particles=[];
  simulationPaused=false;
  lastPieceId=null;
  candidateListEl.innerHTML="";
  fetchCandidateMoves();
}
function updateCandidateListUI(){
  candidateListEl.innerHTML = "";
  topCandidates.forEach((c,i)=>{
    let div = document.createElement("div");
    div.className = "candidate";
    div.style.borderLeft = `10px solid ${c.color}`;
    // Instead of c.flow, we show c.flowDisplay
    div.innerHTML = `
      <h3>${c.action_key}</h3>
      <p>Flow: ${c.flowDisplay || 0}</p>
      <p>Prob: ${( (c.probability||0)*100).toFixed(1)}%</p>
    `;
    div.onclick = ()=> doSelectCandidate(c.action_key);
    candidateListEl.appendChild(div);
  });
}


// ====================== INIT FUNCTION ======================
function init(){
  console.log("[init] Starting front-end Tetris GFlowNet...");
  canvas=document.getElementById("tetrisCanvas");
  ctx=canvas.getContext("2d");
  candidateListEl=document.getElementById("candidateList");
  resetBtn=document.getElementById("resetBtn");

  // Create Tetris + Agent
  game=new TetrisGame();
  agent=new TrajectoryBalanceAgent(0.02); // old approach, not used if NN loaded
  nnModel= new NeuralFlowNet();          // new approach

  // Attempt to load from pretrained_flows_nn.json
  console.log("[init] Attempting to fetch pretrained_flows_nn.json...");
  fetch("pretrained_flows_nn.json")
    .then(resp=>{
      if(!resp.ok){
        throw new Error(`Could not fetch JSON: ${resp.status} ${resp.statusText}`);
      }
      return resp.json();
    })
    .then(jsonData=>{
      console.log("[init] Successfully loaded pretrained_flows_nn.json!");
      nnModel.loadJson(jsonData);
    })
    .catch(err=>{
      console.warn("[init] Could NOT load pretrained_flows_nn.json, continuing with fallback agent:", err);
    })
    .finally(()=>{
      // Start game loop
      console.log("[init] Starting game loop now...");
      setInterval(tickGame, TICK_INTERVAL);
      fetchCandidateMoves();
      resetBtn.addEventListener("click", doResetGame);
      requestAnimationFrame(animate);
    });
}

// ====================== DOMContentLoaded ======================
document.addEventListener("DOMContentLoaded", init);
</script>

<!-- 
   (Line 1670) Final JavaScript for Nav Menu and Sticky Arrow
   (If you don't need this part, remove it or keep it)
-->
<script>
function toggleNavMenu() {
  const nav = document.getElementById('mainNav');
  nav.classList.toggle('show');
}
function scrollDown() {
  window.scrollBy({
    top: window.innerHeight,
    left: 0,
    behavior: 'smooth'
  });
}

/* Intersection observer to highlight sections */
document.addEventListener("DOMContentLoaded", () => {
  const sections = document.querySelectorAll("main section");
  const observer = new IntersectionObserver((entries) => {
    entries.forEach(entry => {
      if (entry.isIntersecting) {
        entry.target.classList.add("active");
      } else {
        entry.target.classList.remove("active");
      }
    });
  }, { threshold: 0.3 });
  sections.forEach(section => observer.observe(section));
});
</script>

<!-- 
   (Line 1699) Particle JS config
   We'll set up the background so it looks dynamic. 
-->
<script>
particlesJS("particles-js", {
  particles: {
    number: { value: 60, density: { enable: true, value_area: 800 } },
    color: { value: "#00bfff" },
    shape: {
      type: "circle",
      stroke: { width: 0, color: "#000" },
      polygon: { nb_sides: 5 }
    },
    opacity: { value: 0.5, random: true },
    size: { value: 3, random: true },
    line_linked: {
      enable: true,
      distance: 150,
      color: "#00bfff",
      opacity: 0.4,
      width: 1
    },
    move: {
      enable: true,
      speed: 2,
      direction: "none",
      random: false,
      straight: false,
      out_mode: "out"
    }
  },
  interactivity: {
    detect_on: "canvas",
    events: {
      onhover: { enable: false },
      onclick: { enable: false }
    }
  },
  retina_detect: true
});
</script>

<script>
  document.addEventListener("DOMContentLoaded", function() {
    if(typeof renderMathInElement==="function"){
      renderMathInElement(document.body, {
        delimiters: [
          {left: '$$', right: '$$', display: true},
          {left: '$', right: '$', display: false},
        ]
      });
    }
  });
</script>
